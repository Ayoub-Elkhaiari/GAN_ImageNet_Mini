# GAN Project for ImageNet Mini

## Overview
This project implements a Generative Adversarial Network (GAN) using PyTorch to generate images similar to those in the ImageNet Mini dataset. The GAN consists of two main components:
- **Generator**: Creates fake images from random noise.
- **Discriminator**: Distinguishes between real images (from the ImageNet Mini dataset) and fake images generated by the Generator.

The project uses the ImageNet Mini dataset to train the GAN and generate new images similar to those in the dataset.

## Project Structure
- `Generator.py`: Contains the definition of the Generator network and its associated loss function.
- `Discriminator.py`: Contains the definition of the Discriminator network and its associated loss function.
- `app.py`: Script to train the GAN using the ImageNet Mini dataset, visualize the results, and monitor losses during training.

## Prerequisites
Before running the project, ensure you have the following installed:
- Python 3.x
- PyTorch
- torchvision
- matplotlib
- tqdm

To install the necessary packages, run:
```bash
pip install torch torchvision matplotlib tqdm
```

## How to Run

1. Clone the repository
First, clone the repository to your local machine using Git:

```bash
git clone https://github.com/Ayoub-Elkhaiari/GAN_ImageNet_Mini.git
cd GAN_ImageNet_Mini
```

2. Install dependencies
Install the necessary dependencies as mentioned in the Prerequisites section.

3. Prepare the dataset
Download the ImageNet Mini dataset and place it in a folder named `all_images` in the project directory under this directory `torchvision.datasets.ImageFolder` is excpecting subfoldersfor classes and because GAN is unsupervised  i putted all images under a folder called `images` subfolder of the `all_image` folder.

4. Train the GAN
To start the training process, run the `app.py` script:

```bash
python app.py
```

During training, the losses for both the generator and the discriminator will be displayed after every few steps, and generated images will be visualized for comparison with real images.

5. View Results
Generated images will be periodically shown using `matplotlib`. At each display step, you'll see fake images generated by the GAN alongside real images from the ImageNet Mini dataset.

6. Modify Hyperparameters
You can modify the hyperparameters in the `app.py` file:

```python
n_epochs = 200
z_dim = 64
display_step = 500
batch_size = 128
lr = 0.00001
```

Feel free to adjust them according to your computational resources and desired output quality.

## Key Components of the Code

### Generator (`Generator.py`)
The Generator network takes random noise as input and produces fake images. It uses a series of linear layers with Batch Normalization and ReLU activation, followed by a Tanh activation for the output.

```python
class Generator(nn.Module):
    def __init__(self, z_dim, im_dim):
        # Neural network structure for the generator
        ...
```

### Discriminator (`Discriminator.py`)
The Discriminator network takes an image and predicts whether it is real or fake. It consists of several linear layers followed by LeakyReLU activation.

```python
class Discriminator(nn.Module):
    def __init__(self, im_dim):
        # Neural network structure for the discriminator
        ...
```

### Training Process (`app.py`)
The main training loop is implemented in `app.py`. It handles:
- Loading and preprocessing the ImageNet Mini dataset
- Training the Generator and Discriminator
- Visualizing results
- Monitoring and displaying losses

## Results
As the training progresses, the generator learns to create more realistic images, while the discriminator learns to better distinguish between real and fake images. The script will display generated images alongside real images at regular intervals during training.

## Notes
- This implementation uses the ImageNet Mini dataset, which consists of 64x64 RGB images.
- The GAN is trained on CPU by default. For faster training, consider modifying the code to use GPU if available.
- The `show_tensor_images` function in `app.py` is used to visualize both generated and real images side by side.

